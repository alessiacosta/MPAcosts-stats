---
title: "Ch3-MPAcosts"
---

# Loading packages needed for the project
```{r}
library(readr)
library(ggplot2)
library(rnaturalearth) # to make a world map
library(rnaturalearthdata) # data for world map with polygons of the coastline only
library(dplyr)
library(sf)
library(ggspatial) # to add spatial elements to a ggplot map
library(car)
library(cmdstanr)      #for cmdstan
library(brms)          #for fitting models in STAN
library(coda)          #for diagnostics
library(bayesplot)     #for diagnostics
library(DHARMa)        #for residual diagnostics
library(rstan)         #for interfacing with STAN
library(emmeans)       #for marginal means etc
library(broom)         #for tidying outputs
library(tidybayes)     #for more tidying outputs
library(ggeffects)     #for partial plots
library(broom.mixed)   #for summarising models
library(ggeffects)     #for partial effects plots
library(bayestestR)    #for ROPE
library(see)           #for some plots
library(patchwork)     #for multiple plots
library(modelsummary)  #for data and model summaries 
library(ggridges)      #for ridge plots 
library(stringr)
library(tidyr)
library(geoR)
library(scales)
#sourcing functions from Murray's github repository
source('helperFunctions.R')
```


# Making a map of the MPAs found
## Loading the map data

```{r}
#upload the right data
fig1 <- read_csv("../Data/fig1.csv")
```

## Making global map with my data
```{r}
# Get world map data
world <- ne_countries(scale = "medium", returnclass = "sf")

png("Map1.png", width = 2500, height = 2000, res = 150)
# Create the world map
# Load the coastline data from rnaturalearth
coastline_data <- ne_coastline(scale = "medium", returnclass = "sf")

# Create the plot
ggplot() +  
  # Plot countries in a very light grey
  geom_sf(data = world, fill = "grey95", color = NA) +  
  # Overlay the coastline in black
  geom_sf(data = coastline_data, color = "black", fill = NA) +  
  # Plot your data points
  geom_point(data = fig1, aes(x = Longitude, y = Latitude), color = "#008080", size = 4) +  
  # Set coordinate system
  coord_sf() +
  # Adjust theme
  theme_minimal() +  
  theme(
    axis.text = element_text(size = 24),
    axis.title = element_blank(),  # Removes axis titles
    axis.line.x = element_line(color = "black", size = 0.5),
    axis.line.y = element_line(color = "black", size = 0.5),
    axis.ticks = element_line(color = "black", size = 0.5),
    panel.grid = element_blank()
  )
dev.off()

```



# Statistics

## Bayesian regression with Gamma distribution - establishment

#### Data preparation
```{r}
#importing establishment data
esubs <- read_csv("../Data/esubs.csv")
#View(esubs)
#removing the last two rows from the dataset cause for some reason it pops up as NAs
#esubs <- head(esubs, -2)
#View(esubs)

#data preparation
esubs = esubs |> 
  mutate(Protection_level=factor(Protection_level, 
                                                levels=c("Fully protected", "Partially protected")), 
         ID=factor(ID)) # this will order them rather than going into alphabetical order 
#View(esubs)
summary(esubs)
```

#### Exploratory data analysis
```{r}
# Data exploration to see what distribution I can use in the model
#looking at distribution for costs/km2 divided by gdp classc
esubs |> ggplot(aes(y=Cost_km)) +
  geom_boxplot()
#making an histogram 
esubs |> ggplot(aes(x=Cost_km)) +
  geom_histogram()

#logging the data before producing the histgram 
esubs |> ggplot(aes(x=log(Cost_km))) +
  geom_histogram()

#logging the axis
esubs |> ggplot(aes(x=Cost_km)) +
  geom_histogram() +
  scale_x_log10()
#preferable to change the axis scale and not change the data, in case of raw data it does not make much difference

#checking for linearity 
esubs |> ggplot(aes(y=Cost_km, x=Years)) +
  geom_point() +
  geom_line(aes(group=ID))
# need this to be more clear to see what whether there are patterns

#making a facet 
esubs |> ggplot(aes(y=Cost_km, x=Years)) +
  geom_point() +
  geom_smooth(method="lm") +
  facet_wrap(~ID)

```

#### Fit the model
```{r}
#starting setting up the model
#model formula
form1 = bf(Cost_km ~ scale(Size) + scale(Years) + Protection_level, family=Gamma(link='log'))
#View(esubs)
# mean for each group and mads for each group for our priors
esubs |> 
  summarise(Median=median(log(Cost_km)), MAD=mad(log(Cost_km)))
  
#looking at priors needed
get_prior(form1, esubs)

#setting my priors
priors = prior(normal(12, 4), class='Intercept') +
  prior(normal(0,4), class='b') +
  prior(gamma(0.1,0.1), class='shape')

# running the model with priors only
esubs.brm1 = brm(form1, 
               data=esubs, 
               prior=priors,
               sample_prior='only', 
               iter= 5000, 
               warmup = 1000, 
               chains=3, 
               cores = 3, 
               thin=5, 
               refresh=0, 
               seed=1, 
               backend = "cmdstanr")

#making a conditional plot
esubs.brm1 |>
  conditional_effects() |> 
  plot(points=TRUE)

#making a conditional plot on a better scale 
esubs.brm1 |>
  conditional_effects() |> 
  plot(points=TRUE) |> 
  wrap_plots() &
  scale_y_log10() # I had to increase the priors because they were not wide enough

# running the model with both priors and data
esubs.brm2 = esubs.brm1 |> 
  update(sample_prior = 'yes', refresh=0)

#Assess priors and posteriors
esubs.brm2 |> SUYR_prior_and_posterior()

#Produce the same conditional plot but with the posteriors
esubs.brm2 |>
  conditional_effects() |> 
  plot(points=TRUE) |> 
  wrap_plots() &
  scale_y_log10()
#priors are not influential but there is very little data
```

#### MCMC sampling diagnostics
```{r}
#trace plot 
esubs.brm2$fit |> stan_trace()

#border correlarion
esubs.brm2$fit |> stan_ac()

#chain convergence
esubs.brm2$fit |> stan_rhat()
#all values less than 1.01

#effective sample size
esubs.brm2$fit |> stan_ess() # there are no issues here
#values higher than 0.5 and as close to 1 as possible, otherwise it means that the sampler drifted away

#check the densities
esubs.brm2$fit |> stan_dens(separate_chains=TRUE)
#this plot is good if we have high hats 

```

#### Model validation
```{r}
#probability check
esubs.brm2 |> pp_check(type='dens_overlay', ndraws=100) + 
  xlim(0, 6.0e+06)
#not the best fit it could be 

#sim residuals 
esubs.resids  = make_brms_dharma_res(esubs.brm2, integerResponse= TRUE)
testUniformity(esubs.resids)
#simulated residuals are not too bad, acceptable

#check no patterns in the residuals 
plotResiduals(esubs.resids, quantreg = TRUE)
#no issues here, looks half decent
#the diagnostics look fine but we know we need to check other things based on the pp check

#test for correlation 
#esubs.resids |> testTemporalAutocorrelation(time=esubs$Years)
#check if correlation between closer days is the same as correlation in apart days. this function gives error because residuals need to be aggregated 

#this is not working
#aggregate the residuals so that all day 1 and all day etc. have the same residuals to have a singular auto correlation plot 
#esubs.resids1 = esubs.resids |> 
  #recalculateResiduals(group=esubs$Years, aggregateBy = sum)
#now we can use the temporal autocorrelation plot 
#esubs.resids1 |> testTemporalAutocorrelation(time=unique(esubs$Years))
#check for autocorrelation 
#autocor_check(esubs, esubs.brm2, variable = "Years", n.sim=250)
#I do not think I need to check for autocorrelation with this data as it is not sampling data over time
```

#### Results
```{r}
# generic summary 
esubs.brm2 |> summary() 

#thorough results
esubs.brm2 |> 
  as_draws_df() |>  
  dplyr::select(matches("^b_.*")) |> 
  exp() |> 
  summarise_draws(median, 
                  HDInterval::hdi,
                  rhat, 
                  ess_bulk,
                  Pl=~mean(.x<1), 
                  Pg=~mean(.x>1))

#Paritally protected (1-0.062)*100= 3% decresase in cost_km in partially protected areas than in fully protected areas, and we have strong evidence because we look a Pl for evidence- 99%

#the amount of variability explained by the model -quasi R sqaured
esubs.brm2 |> bayes_R2(summary=FALSE) |> median_hdci()
#we are explaining 40% of the variance with this model -  which should be a pretty good fit for the model
```

#### Plot results - predictions
```{r}
# Filter out NAs in the relevant columns
esubs_clean_size <- esubs |> 
  filter(!is.na(Size), !is.na(Years), !is.na(Protection_level))

# Generate prediction data
pred_size <- emmeans(
  esubs.brm2,
  ~ Size | Protection_level,
  at = list(Size = seq(min(esubs_clean_size$Size), max(esubs_clean_size$Size), length.out = 100),
            Years = mean(esubs_clean_size$Years, na.rm = TRUE)),
  type = "response"
) |> as.data.frame()

#producing a predicted ggplot
esize = ggplot(pred_size, aes(x = Size, y = response, color = Protection_level, fill = Protection_level)) +
  geom_line(size = 0.8) +  # thinner line
  geom_ribbon(aes(ymin = lower.HPD, ymax = upper.HPD), alpha = 0.2, color = NA) +
  scale_y_log10() +
  theme_bw() +
  theme(text = element_text(family = "serif")) +
  scale_fill_manual(
    name = "Protection status",
    values = c("Fully protected" = "#0072B2", "Partially protected" = "#D55E00"),
    labels = c("Fully protected" = "Fully protected", "Partially protected" = "Multi-use areas")
  ) +
  scale_color_manual(
    name = "Protection status",
    values = c("Fully protected" = "#0072B2", "Partially protected" = "#D55E00"),
    labels = c("Fully protected" = "Fully protected", "Partially protected" = "Multi-use areas")
  ) +
  labs(
    x = "Size (km²)",
    y = "Establishment cost/km²"
  )

# Generate prediction data
pred_size1 <- emmeans(
  esubs.brm2,
  ~ Years | Protection_level,
  at = list(Years = seq(min(esubs_clean_size$Years), max(esubs_clean_size$Years), length.out = 100),
            Size = mean(esubs_clean_size$Size, na.rm = TRUE)),
  type = "response"
) |> as.data.frame()

#plot prediction
png("years.png", width = 1800, height = 1000, res = 300)
 #eyears = 
   ggplot(pred_size1, aes(x = Years, y = response, color = Protection_level, fill = Protection_level)) +
  geom_line(size = 0.8) +  # thinner line
  geom_ribbon(aes(ymin = lower.HPD, ymax = upper.HPD), alpha = 0.2, color = NA) +
  scale_y_log10() +
  theme_bw() +
   theme(text = element_text(family = "serif")) +
  labs(
    x = "Establishment years",
    y = "Estimated cost per km²"
  ) +
  scale_fill_manual(
    name = "Protection status",
    values = c("Fully protected" = "#0072B2", "Partially protected" = "#D55E00"),
    labels = c("Fully protected" = "Fully protected", "Partially protected" = "Multi-use areas")
  ) +
  scale_color_manual(
    name = "Protection status",
    values = c("Fully protected" = "#0072B2", "Partially protected" = "#D55E00"),
    labels = c("Fully protected" = "Fully protected", "Partially protected" = "Multi-use areas")
  )
 dev.off()
```







## Bayesian regression with Gamma distribution - maintenance with subs

#### Data preparation
```{r}
#using maintenance coded with subs 
msubs <- read_csv("../Data/msubs.csv")
#View(msubs)
#preparing data
msubs = msubs |> mutate(Protection_level=factor(Protection_level, 
                                                levels=c("Fully protected", "Partially protected")), # this will order them rather than going into alphabetical order 
                        Cost_class=factor(Cost_class, 
                                          levels=c("Maintenance", "Administration", "Enforcement", "Management")),
                        Management=factor(Management, 
                                          levels=c(1,0)), 
                        Administration=factor(Administration, 
                                              levels=c(1,0)), 
                        Enforcement=factor(Enforcement, 
                                           levels=c(1,0)), 
                        ID=factor(ID))
```

#### Exploratory data analysis
```{r}
#View(msubs)
## Data exploration to see what distribution I can use in the model
#looking at distribution for costs/km2 divided by gdp classc
msubs |> ggplot(aes(y=Cost_km)) +
  geom_boxplot()
#making an histogram 
msubs |> ggplot(aes(x=Cost_km)) +
  geom_histogram()

#logging the data before producing the histgram 
msubs |> ggplot(aes(x=log(Cost_km))) +
  geom_histogram()

#logging the axis
msubs |> ggplot(aes(x=Cost_km)) +
  geom_histogram() +
  scale_x_log10()
#preferable to change the axis scale and not change the data, in case of raw data it does not make much difference

#checking for linearity 
msubs |> ggplot(aes(y=Cost_km, x=Size)) +
  geom_point() +
  geom_line(aes(group=ID))
# need this to be more clear to see what whether there are patterns

#making a facet 
esubs |> ggplot(aes(y=Cost_km, x=Size)) +
  geom_point() +
  geom_smooth(method="lm") +
  facet_wrap(~Protection_level)
```

#### Fit the model
```{r}
#model formula
form = bf(Cost_km ~ scale(Size) + Management + Administration + Enforcement + Protection_level, family=Gamma(link='log'))
# mean for each group and mads for each group for our priors
msubs |> 
  summarise(Median=median(log(Cost_km)), MAD=mad(log(Cost_km)))

#getting standard priors
get_prior(form, data=msubs)

#setting priors
priors = prior(normal(8, 3), class='Intercept') +
  prior(normal(0,3), class='b') +
  prior(gamma(0.1,0.1), class='shape')

# running the model with priors only
msubs.brm1 = brm(form, 
               data=msubs, 
               prior=priors,
               sample_prior='only', 
               iter= 5000, 
               warmup = 1000, 
               chains=3, 
               cores = 3, 
               thin=5, 
               refresh=0, 
               seed=1, 
               backend = "cmdstanr")

#making a conditional plot
msubs.brm1 |>
  conditional_effects() |> 
  plot(points=TRUE, ask=FALSE, plot=FALSE) |> 
  wrap_plots() &
  scale_y_log10()

# running the model with both priors and data
msubs.brm2 = msubs.brm1 |> 
  update(sample_prior = 'yes', refresh=0)

#Assess priors and posteriors
msubs.brm2 |> SUYR_prior_and_posterior()

#Produce the same conditional plot but with the posteriors
msubs.brm2 |>
  conditional_effects() |> 
  plot(points=TRUE) |> 
  wrap_plots() &
  scale_y_log10()
#priors are not influential but there is very little data
```

#### MCMC sampling diagnostics
```{r}
#trace plot 
msubs.brm2$fit |> stan_trace()

#border correlarion
msubs.brm2$fit |> stan_ac()

#chain convergence
msubs.brm2$fit |> stan_rhat()

#effective sample size
msubs.brm2$fit |> stan_ess() # there are no issues here

#check the densities
esubs.brm2$fit |> stan_dens(separate_chains=TRUE)
#this plot is good if we have high hats 
```

#### Model validation
```{r}
#probability check
msubs.brm2 |> pp_check(type='dens_overlay', ndraws=100)
#not the best fit it could be 

#sim residuals 
msubs.resids  = make_brms_dharma_res(msubs.brm2, integerResponse= TRUE)
testUniformity(msubs.resids)
#simulated residuals are not too bad, acceptable

#check no patterns in the residuals 
plotResiduals(msubs.resids, quantreg = TRUE)
#red lines that there might be some trends occurring, because the line is high and it decreases. 
#without lines we would have not noticed the trends
```

#### Results
```{r}
# generic summary 
msubs.brm2 |> summary() 

#thorough results
msubs.brm2 |> 
  as_draws_df() |>  
  dplyr::select(matches("^b_.*")) |> 
  exp() |> 
  summarise_draws(median, 
                  HDInterval::hdi,
                  rhat, 
                  ess_bulk,
                  Pl=~mean(.x<1), 
                  Pg=~mean(.x>1))

#Paritally protected (1-0.062)*100= 3% decresase in cost_km in partially protected areas than in fully protected areas, and we have strong evidence because we look a Pl for evidence- 99%

#the amount of variability explained by the model -quasi R sqaured
msubs.brm2 |> bayes_R2(summary=FALSE) |> median_hdci()
#we are explaining 10% of the variance with this model -  which should be a pretty good fit for the model
```


#### Plot results - predictions
```{r}
#prediction of the maintenance costs/km2 per year
pred_size2 <- emmeans(
  msubs.brm2,
  ~ Size | Protection_level,
  at = list(
    Size = seq(min(msubs$Size), max(msubs$Size), length.out = 100),
    Management = levels(msubs$Management)[1],       # fix to first level
    Administration = levels(msubs$Administration)[1],
    Enforcement = levels(msubs$Enforcement)[1]),
  type = "response") |> 
  as.data.frame()

#prediction plot
msize = ggplot(pred_size2, aes(x = Size, y = response, color = Protection_level, fill = Protection_level)) +
  geom_line(size = 0.8) +
  geom_ribbon(aes(ymin = lower.HPD, ymax = upper.HPD), alpha = 0.2, color = NA) +
  scale_y_log10(labels = label_scientific()) +
  scale_x_continuous(labels = label_scientific()) +  # Scientific notation on x-axis
  theme_bw() +
  theme(text = element_text(family = "serif")) +
  labs(
    x = "Size (km²)",
    y = "Maintenance cost/km² p.a.") +
  scale_fill_manual(
    name = "Protection status",
    values = c("Fully protected" = "#0072B2", "Partially protected" = "#D55E00"),
    labels = c("Fully protected" = "Fully protected", "Partially protected" = "Multi-use areas")
  ) +
  scale_color_manual(
    name = "Protection status",
    values = c("Fully protected" = "#0072B2", "Partially protected" = "#D55E00"),
    labels = c("Fully protected" = "Fully protected", "Partially protected" = "Multi-use areas")
  )

```







## Summary plots
### Combining plots

##### Prediction of costs/km2 with change in size
```{r}
#hypothesis 1 
# Average response at each Size value for maintenance
pred_maint <- pred_size2 |> 
  group_by(Size) |> 
  summarise(
    response = mean(response),
    lower.HPD = mean(lower.HPD),
    upper.HPD = mean(upper.HPD)
  )
# Establishment cost prediction
pred_estab <- pred_size |> 
  group_by(Size) |> 
  summarise(
    response = mean(response),
    lower.HPD = mean(lower.HPD),
    upper.HPD = mean(upper.HPD)
  )
#adding 'type' so I can assign different colors to them 
pred_maint$type <- "Maintenance"
pred_estab$type <- "Establishment"
#combine the two into one dataframe
pred_combined <- bind_rows(pred_maint, pred_estab)

# Plot
png("h1.png", width = 1400, height = 800, res = 300)
scales = ggplot(pred_combined, aes(x = Size, y = response, color = type, fill = type)) +
  geom_line(size = 0.8) +
  geom_ribbon(aes(ymin = lower.HPD, ymax = upper.HPD), alpha = 0.2, color = NA) +
  scale_x_continuous(labels = label_scientific()) +
  scale_y_log10(labels = label_scientific()) +
  theme_bw() +
  theme(text = element_text(family = "serif"),
    legend.position = c(0.95, 0.98),  # Top right corner
    legend.justification = c("right", "top"),  # Anchor to top right
    legend.background = element_rect(fill = "transparent", color = NA)) +
  labs(
    x = "Size (km²)",
    y = "Cost/km²",
    color = "Cost type",
    fill = "Cost type"
  ) +
  scale_color_manual(values = c("Maintenance" = "#0072B2", "Establishment" = "#D55E00")) +
  scale_fill_manual(values = c("Maintenance" = "#0072B2", "Establishment" = "#D55E00"))
dev.off()
#the prediction becomes very close to zero because we are using a log link distribution but never negative --> this is fro when I am not logging 10 the y axis

#hypothesis n 4
png("economiesofscales.png", width = 3300, height = 1800, res = 300)  # adjust as needed
plots1 = esize / msize + plot_layout(guides = 'collect') 
plots2 = scales | plots1
plots2 + plot_annotation(tag_levels = 'A') 
dev.off()
```

